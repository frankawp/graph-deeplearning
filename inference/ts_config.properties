# TorchServe配置

# 推理配置
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082

# 模型配置
number_of_netty_threads=4
job_queue_size=100
model_store=/data/graph_learning/inference/model-store

# 性能配置
default_workers_per_model=4
default_response_timeout=120

# 日志配置
async_logging=true
